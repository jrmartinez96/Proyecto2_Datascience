View(nn_ventas_centroamerica)
nn_ventas_centroamerica <- subset(ventas.centroamerica, subset = Producto %in% c(4123660489,4123310128,4123310128,4123320382,4123320398,4323580808,4123210921,4123210924,4123660778,4323580477,4123320383,4123660107,4123660184,4123310157,4323580520,4123660683,4323621560,4123660798,4123660738,4123660155,4123320424))
View(nn_ventas_centroamerica)
porcentaje<-0.7
set.seed(678)
corte_nn<-sample(nrow(nn_ventas_centroamerica),nrow(nn_ventas_centroamerica)*porcentaje)
train_nn<-datosTraining[corte_nn,]
test_nn<-datosTraining[-corte_nn,]
corte_nn<-sample(nrow(nn_ventas_centroamerica),nrow(nn_ventas_centroamerica)*porcentaje)
train_nn<-nn_ventas_centroamerica[corte_nn,]
test_nn<-nn_ventas_centroamerica[-corte_nn,]
View(train_nn)
View(test_nn)
nn_ventas_centroamerica <- nn_ventas_centroamerica[,num <- unlist(lapply(ventas.centroamerica, is.numeric))]
View(nn_ventas_centroamerica)
source('C:/Users/anali/Desktop/Pablito/octavo_semestre/Data science/Proyecto2_Datascience/testDeImportacion.R', encoding = 'UTF-8')
nn_ventas_centroamerica[is.na(nn_ventas_centroamerica)] <- 0
View(nn_ventas_centroamerica)
corte_nn<-sample(nrow(nn_ventas_centroamerica),nrow(nn_ventas_centroamerica)*porcentaje)
train_nn<-nn_ventas_centroamerica[corte_nn,]
test_nn<-nn_ventas_centroamerica[-corte_nn,]
nn_ventas_centroamerica <- scale(nn_ventas_centroamerica)
View(nn_ventas_centroamerica)
corte_nn<-sample(nrow(nn_ventas_centroamerica),nrow(nn_ventas_centroamerica)*porcentaje)
train_nn<-nn_ventas_centroamerica[corte_nn,]
test_nn<-nn_ventas_centroamerica[-corte_nn,]
?neuralnet
source('C:/Users/anali/Desktop/Pablito/octavo_semestre/Data science/Proyecto2_Datascience/testDeImportacion.R', encoding = 'UTF-8')
corte_nn<-sample(nrow(nn_ventas_centroamerica),nrow(nn_ventas_centroamerica)*porcentaje)
train_nn<-nn_ventas_centroamerica[corte_nn,]
test_nn<-nn_ventas_centroamerica[-corte_nn,]
View(test_nn)
View(train_nn)
nn_model <- neuralnet(Pronostico~., data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
source('C:/Users/anali/Desktop/Pablito/octavo_semestre/Data science/Proyecto2_Datascience/testDeImportacion.R', encoding = 'UTF-8')
nn_model <- neuralnet(Pronostico ~ Costo, data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
nn_model <- neuralnet(Pronostico ~ ., data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
nn_model <- neuralnet(Pronostico~., data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
nn_model <- neuralnet(Pronostico ~., data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
nn_model <- neuralnet(Pronostico ~ Costo + Utilidad + Margen + ´Pedido Real´ + Ratio, = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
nn_model <- neuralnet(Pronostico ~ Costo + Utilidad + Margen + ´Pedido Real´ + Ratio, data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
nn_model <- neuralnet(Pronostico ~ Costo + Utilidad + Margen + Ratio, data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
nn_model <- neuralnet(Pronostico ~ `Unidades Vendidas` + Costo + Utilidad + Margen + Ratio, data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
colnames(train_nn) <- c("precio_catalogo","precio_sin_iva","pronostico","uni_vendidas","venta_neta","costo","utilidad","margen","pedido_real","ratio","porcentaje","porcentaje_2")
colnames(train_nn) <- c("precio_catalogo","precio_sin_iva","pronostico","uni_vendidas","venta_neta","costo","utilidad","margen","pedido_real","ratio","porcentaje","porcentaje_2","pais_numero","categoria_numero","canalventa_numero","paginacion_numero")
View(train_nn)
nn_model <- neuralnet(Pronostico ~., data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
test_nn<-nn_ventas_centroamerica[-corte_nn,]
colnames(test_nn) <- c("precio_catalogo","precio_sin_iva","pronostico","uni_vendidas","venta_neta","costo","utilidad","margen","pedido_real","ratio","porcentaje","porcentaje_2","pais_numero","categoria_numero","canalventa_numero","paginacion_numero")
nn_model <- neuralnet(pronostico ~., data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
nn_model$result.matrix
plot(nn_model)
nn_model <- neuralnet(pronostico ~., data = train_nn, hidden=c(4,1), linear.output=FALSE, threshold=0.01 )
plot(nn_model)
nn_model <- neuralnet(pronostico ~., data = train_nn, hidden=c(2,1), linear.output=FALSE, threshold=0.01 )
temp_test <- subset(test_nn, select = c("precio_catalogo","precio_sin_iva","uni_vendidas","venta_neta","costo","utilidad","margen","pedido_real","ratio","porcentaje","porcentaje_2","pais_numero","categoria_numero","canalventa_numero","paginacion_numero"))
View(temp_test)
nn.results <- compute(nn_model, temp_test)
head(test_nn)
results <- data.frame(actual = test_nn$pronostico, prediction = nn.results$net.result)
test_nn<-nn_ventas_centroamerica[-corte_nn,]
test_nn$pronostico
is.atomic(temp_test)
test_nn <- as.data.frame(test_nn)
source('C:/Users/anali/Desktop/Pablito/octavo_semestre/Data science/Proyecto2_Datascience/testDeImportacion.R', encoding = 'UTF-8')
results <- data.frame(actual = test_nn$Pronostico, prediction = nn.results$net.result)
results
roundedresults<-sapply(results,round,digits=0)
roundedresultsdf=data.frame(roundedresults)
attach(roundedresultsdf)
table(actual,prediction)
?neuralnet
nn_model <- neuralnet(pronostico ~., data = train_nn, hidden=c(4,3,2,1), linear.output=FALSE, threshold=0.01 )
temp_test <- subset(test_nn, select = c("precio_catalogo","precio_sin_iva","uni_vendidas","venta_neta","costo","utilidad","margen","pedido_real","ratio","porcentaje","porcentaje_2","pais_numero","categoria_numero","canalventa_numero","paginacion_numero"))
nn.results <- compute(nn_model, temp_test)
results <- data.frame(actual = test_nn$Pronostico, prediction = nn.results$net.result)
roundedresults<-sapply(results,round,digits=0)
roundedresultsdf=data.frame(roundedresults)
attach(roundedresultsdf)
table(actual,prediction)
plot(nn_model)
plot(nn_model)
results
table(actual,prediction)
nn_ventas_centroamerica <- subset(ventas.centroamerica, subset = Producto %in% c(4123660489,4123310128,4123310128,4123320382,4123320398,4323580808,4123210921,4123210924,4123660778,4323580477,4123320383,4123660107,4123660184,4123310157,4323580520,4123660683,4323621560,4123660798,4123660738,4123660155,4123320424))
nn_ventas_centroamerica <- nn_ventas_centroamerica[,num <- unlist(lapply(ventas.centroamerica, is.numeric))]
nn_ventas_centroamerica[is.na(nn_ventas_centroamerica)] <- 0
corte_nn<-sample(nrow(nn_ventas_centroamerica),nrow(nn_ventas_centroamerica)*porcentaje)
train_nn<-nn_ventas_centroamerica[corte_nn,]
test_nn<-nn_ventas_centroamerica[-corte_nn,]
test_nn <- as.data.frame(test_nn)
colnames(train_nn) <- c("precio_catalogo","precio_sin_iva","pronostico","uni_vendidas","venta_neta","costo","utilidad","margen","pedido_real","ratio","porcentaje","porcentaje_2","pais_numero","categoria_numero","canalventa_numero","paginacion_numero")
colnames(test_nn) <- c("precio_catalogo","precio_sin_iva","pronostico","uni_vendidas","venta_neta","costo","utilidad","margen","pedido_real","ratio","porcentaje","porcentaje_2","pais_numero","categoria_numero","canalventa_numero","paginacion_numero")
View(train_nn)
nn_model <- neuralnet(pronostico ~., data = train_nn, hidden=c(4,3,2,1), linear.output=FALSE, threshold=0.01 )
temp_test <- subset(test_nn, select = c("precio_catalogo","precio_sin_iva","uni_vendidas","venta_neta","costo","utilidad","margen","pedido_real","ratio","porcentaje","porcentaje_2","pais_numero","categoria_numero","canalventa_numero","paginacion_numero"))
nn.results <- compute(nn_model, temp_test)
results <- data.frame(actual = test_nn$Pronostico, prediction = nn.results$net.result)
roundedresults<-sapply(results,round,digits=0)
roundedresultsdf=data.frame(roundedresults)
attach(roundedresultsdf)
table(actual,prediction)
source('C:/Users/anali/Desktop/Pablito/octavo_semestre/Data science/Proyecto2_Datascience/testDeImportacion.R', encoding = 'UTF-8')
?source
install.packages("openxlsx")
install.packages("forecast")
install.packages("fUnitRoots")
install.packages("ggfortify")
install.packages("xts")
library(forecast)
library(tseries)
library(fUnitRoots)
library(ggfortify)
library(xts)
library("openxlsx")
PagGuate <- read.xlsx("PAG-GT.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagGuate$Pais<-"Guatemala"
View(head(PagGuate))
PagHon <- read.xlsx("PAG-HO.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagHon$Pais<-"Honduras"
View(head(PagHon))
PagEL <- read.xlsx("PAG-EL.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagEL$Pais<-"El Salvador"
View(head(PagEL))
PagNi <- read.xlsx("PAG-NI.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagNi$Pais<-"Nicaragua"
View(head(PagNi))
PagCentroamerica <- rbind(PagGuate, PagHon, PagEL, PagNi)
View(PagCentroamerica)
PagCentroamerica$Año.Mes<-as.factor(PagCentroamerica$Año.Mes)
PagGuate <- read.xlsx("PAG-GT.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagGuate <- read.xlsx("PAG-GT.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagGuate <- read.xlsx("PAGS/PAG-GT.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagGuate$Pais<-"Guatemala"
View(head(PagGuate))
PagHon <- read.xlsx("PAGS/PAG-HO.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagHon$Pais<-"Honduras"
View(head(PagHon))
PagEL <- read.xlsx("PAGS/PAG-EL.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagEL$Pais<-"El Salvador"
View(head(PagEL))
PagNi <- read.xlsx("PAGS/PAG-NI.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagNi$Pais<-"Nicaragua"
View(head(PagNi))
PagCentroamerica <- rbind(PagGuate, PagHon, PagEL, PagNi)
View(PagCentroamerica)
PagCentroamerica$Año.Mes<-as.factor(PagCentroamerica$Año.Mes)
PagGuate <- read.xlsx("PAGS/PAG-GT.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagGuate$Pais<-"Guatemala"
View(head(PagGuate))
PagHon <- read.xlsx("PAGS/PAG-HO.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagHon$Pais<-"Honduras"
View(head(PagHon))
PagEL <- read.xlsx("PAGS/PAG-EL.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagEL$Pais<-"El Salvador"
View(head(PagEL))
PagNi <- read.xlsx("PAGS/PAG-NI.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagNi$Pais<-"Nicaragua"
View(head(PagNi))
PagCentroamerica <- rbind(PagGuate, PagHon, PagEL, PagNi)
View(PagCentroamerica)
PagCentroamerica$Año.Mes<-as.factor(PagCentroamerica$Año.Mes)
p_uv_pro <- ventas.centroamerica[,c(2,10,11)]
p_uv_pro <- PagCentroamerica[,c(2,10,11)]
View(p_uv_pro)
p_uv_pro <- PagCentroamerica[,c(1,2,10,11)]
View(p_uv_pro)
p_uv_pro <- PagCentroamerica[,c(2,10,11)]
p_uv_pro <- aggregate(cbind(p_uv_pro$Pronostico, p_uv_pro$Unidades.Vendidas),by=list(Producto=p_uv_pro$Producto), FUN=sum)
View(p_uv_pro)
p_uv_pro$diferencia <- p_uv_pro$V1 - p_uv_pro$V2
p_uv_pro_asc <- p_uv_pro[order(p_uv_pro$diferencia),]
p_uv_pro_desc <- p_uv_pro[order(-p_uv_pro$diferencia),]
View(p_uv_pro_asc)
?subset
factor(PagCentroamerica$Año.Mes)
vamoaver <- subset(PagCentroamerica, Año.mes==201701)
library(dplyr)
vamoaver <- subset(PagCentroamerica, subset = Año.mes %in% 201701)
PagCentroamerica$Año.Mes <- PagCentroamerica$anomes
head(PagCentroamerica)
View(PagCentroamerica)
PagCentroamerica <- rbind(PagGuate, PagHon, PagEL, PagNi)
PagCentroamerica$Anomes <- PagCentroamerica$Año.Mes
View(PagCentroamerica)
PagCentroamerica$Año.Mes <- NULL
View(PagCentroamerica)
str(PagCentroamerica)
vamoaver <- subset(PagCentroamerica, Anomes == "201701")
View(vamoaver)
ahorasivamoaver <- subset(vamoaver, Producto == "4123310128")
View(ahorasivamoaver)
vamoaver <- subset(PagCentroamerica, Anomes == "201801")
ahorasivamoaver <- subset(vamoaver, Producto == "4123310128")
View(ahorasivamoaver)
View(vamoaver)
vamoaver <- subset(PagCentroamerica, Anomes == "2018")
View(vamoaver)
vamoaver <- subset(PagCentroamerica, Anomes %in% c("201801","201802","201803","201804","201805","201806","201807","201808","201809"))
View(vamoaver)
# -> Cargamos los datos de cada país individual, los juntamos para formar centroamérica
PagGuate <- read.xlsx("PAGS/PAG-GT.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagGuate$Pais<-"Guatemala"
PagHon <- read.xlsx("PAGS/PAG-HO.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagHon$Pais<-"Honduras"
PagEL <- read.xlsx("PAGS/PAG-EL.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagEL$Pais<-"El Salvador"
PagNi <- read.xlsx("PAGS/PAG-NI.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagNi$Pais<-"Nicaragua"
#PagCentroamerica es la unión de todos los individuales
PagCentroamerica <- rbind(PagGuate, PagHon, PagEL, PagNi)
names(PagCentroamerica)[1] = "anomes"
View(PagCentroamerica)
View(PagCentroamerica)
PagCentroamerica$anomes<-as.factor(PagCentroamerica$anomes)
p_uv_pro <- PagCentroamerica[,c(2,10,11)]
p_uv_pro <- aggregate(cbind(p_uv_pro$Pronostico, p_uv_pro$Unidades.Vendidas),by=list(Producto=p_uv_pro$Producto), FUN=sum)
names(p_uv_pro)[2][3] = c("pronostico", "un_vendidas")
View(p_uv_pro)
names(p_uv_pro) = c("producto","pronostico", "un_vendidas")
p_uv_pro$diferencia <- p_uv_pro$pronostico - p_uv_pro$un_vendidas
p_uv_pro_asc <- p_uv_pro[order(p_uv_pro$diferencia),]
p_uv_pro_desc <- p_uv_pro[order(-p_uv_pro$diferencia),]
View(p_uv_pro_asc)
faltantes <- p_uv_pro[order(p_uv_pro$diferencia),]
View(Faltantes)
View(faltantes)
View(PagCentroamerica)
lady_shampoo <- subset(PagCentroamerica, Producto = 4123310128)
View(lady_shampoo)
str(PagCentroamerica)
lady_shampoo <- subset(PagCentroamerica, Producto == "4123310128")
View(lady_shampoo)
lady_shampoo <- subset(PagCentroamerica, Producto = "4123310128")
View(lady_shampoo)
lady_shampoo <- subset(PagCentroamerica, Producto == "4123310128")
lady_shampoo <- subset(PagCentroamerica, Producto %in% "4123310128")
lady_shampoo <- subset(PagCentroamerica, Producto %in% "4123310128")
lady_shampoo <- PagCentroamerica[which(PagCentroamerica$Producto=="4123310128")]
View(lady_shampoo)
lady_shampoo <- subset(PagCentroamerica, subset = Producto %in% "4123310128")
lady_shampoo <- subset(PagCentroamerica, subset = Producto %in% 4123310128)
str(PagCentroamerica)
lady_shampoo <- subset(PagCentroamerica, Producto == "4123310128 ")
View(lady_shampoo)
lady_shampoo <- subset(PagCentroamerica, Producto == "4124160061 ")
View(lady_shampoo)
lady_shampoo <- subset(PagCentroamerica, Producto == "4123310128 ")
View(lady_shampoo)
lady_shampoo[is.null(lady_shampoo)] <- 0
View(lady_shampoo)
?is.nukk
?is.null
lady_shampoo[lady_shampoo == NULL] <- 0
lady_shampoo[lady_shampoo == "NULL"] <- 0
View(lady_shampoo)
lady_shampoo_num <- lady_shampoo[,unlist(lapply(ventas.centroamerica, is.numeric))]
lady_shampoo_num <- lady_shampoo[,unlist(lapply(lady_shampoo, is.numeric))]
View(lady_shampoo_num)
str(lady_shampoo)
lady_shampoo$Pagina <- as.numeric(lady_shampoo$Pagina)
str(lady_shampoo)
# -> Cargamos los datos de cada país individual, los juntamos para formar centroamérica
PagGuate <- read.xlsx("PAGS/PAG-GT.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagGuate$Pais<-"Guatemala"
PagHon <- read.xlsx("PAGS/PAG-HO.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagHon$Pais<-"Honduras"
PagEL <- read.xlsx("PAGS/PAG-EL.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagEL$Pais<-"El Salvador"
PagNi <- read.xlsx("PAGS/PAG-NI.xlsx", sheet = 1, startRow = 1, colNames = TRUE)
PagNi$Pais<-"Nicaragua"
#PagCentroamerica es la unión de todos los individuales
PagCentroamerica <- rbind(PagGuate, PagHon, PagEL, PagNi)
#Renombramos la columna de Año.Mes
names(PagCentroamerica)[1] = "anomes"
PagCentroamerica$anomes<-as.factor(PagCentroamerica$anomes)
PagCentroamerica[is.null(PagCentroamerica)] <- 0
PagCentroamerica[PagCentroamerica == "NULL"] <- 0
PagCentroamerica$Pagina <- as.numeric(PagCentroamerica$Pagina)
PagCentroamerica$Precio.Catalogo <- as.numeric(PagCentroamerica$Precio.Catalogo)
PagCentroamerica$`Precio.Vta.s/iva`<- as.numeric(PagCentroamerica$`Precio.Vta.s/iva`)
PagCentroamerica$Costo <- as.numeric(PagCentroamerica$Costo)
str(PagCentroamerica)
lady_shampoo <- subset(PagCentroamerica, Producto == "4123310128 ")
lady_shampoo_num <- lady_shampoo[,unlist(lapply(lady_shampoo, is.numeric))]
View(lady_shampoo_num)
library(neuralnet)
porcentaje <- 80
corte_nn<-sample(nrow(lady_shampoo_num),nrow(lady_shampoo_num)*porcentaje)
train_nn<-lady_shampoo_num[corte_nn,]
test_nn<-lady_shampoo_num[-corte_nn,]
porcentaje <- 0.8
corte_nn<-sample(nrow(lady_shampoo_num),nrow(lady_shampoo_num)*porcentaje)
train_nn<-lady_shampoo_num[corte_nn,]
test_nn<-lady_shampoo_num[-corte_nn,]
View(train_nn)
nn_model <- neuralnet(Unidades.Vendidas ~., data = train_nn, hidden=c(4,3,2,1), linear.output=FALSE, threshold=0.01 )
nn_model <- neuralnet(Unidades.Vendidas~., data = train_nn, hidden=c(4,3,2,1), linear.output=FALSE, threshold=0.01 )
nn_model <- neuralnet(Pronostico~., data = train_nn, hidden=c(4,3,2,1), linear.output=FALSE, threshold=0.01 )
nn_model <- neuralnet(Pronostico~Pagina, data = train_nn, hidden=c(4,3,2,1), linear.output=FALSE, threshold=0.01 )
PagCentroamerica[is.na(PagCentroamerica)] <- 0
PagCentroamerica$Pagina <- as.numeric(PagCentroamerica$Pagina)
PagCentroamerica$Precio.Catalogo <- as.numeric(PagCentroamerica$Precio.Catalogo)
PagCentroamerica$`Precio.Vta.s/iva`<- as.numeric(PagCentroamerica$`Precio.Vta.s/iva`)
PagCentroamerica$Costo <- as.numeric(PagCentroamerica$Costo)
#Seleccionamos un dataframe solo con el producto, las unidades vendidas, y el pronostico por unidad
p_uv_pro <- PagCentroamerica[,c(2,10,11)]
#Agrupamos por producto, y sumamos sus u/v y pronosticos a traves de los años
p_uv_pro <- aggregate(cbind(p_uv_pro$Pronostico, p_uv_pro$Unidades.Vendidas),by=list(Producto=p_uv_pro$Producto), FUN=sum)
#Cambiar nombres
names(p_uv_pro) = c("producto","pronostico", "un_vendidas")
#Hacemos una diferencia
p_uv_pro$diferencia <- p_uv_pro$pronostico - p_uv_pro$un_vendidas
#Faltantes
faltantes <- p_uv_pro[order(p_uv_pro$diferencia),]
#Excedente
#p_uv_pro_desc <- p_uv_pro[order(-p_uv_pro$diferencia),]3
# --> Analizamos cada uno de los primeros cinco productos
#Producto numero 1 - DUO SOFT LADY SHAMPOO + SPRAY
lady_shampoo <- subset(PagCentroamerica, Producto == "4123310128 ")
#Utilizamos unicamente las variables numericas para hacer el modelo de red neuronal
lady_shampoo_num <- lady_shampoo[,unlist(lapply(lady_shampoo, is.numeric))]
porcentaje <- 0.8
corte_nn<-sample(nrow(lady_shampoo_num),nrow(lady_shampoo_num)*porcentaje)
train_nn<-lady_shampoo_num[corte_nn,]
test_nn<-lady_shampoo_num[-corte_nn,]
nn_model <- neuralnet(Pronostico~Pagina, data = train_nn, hidden=c(4,3,2,1), linear.output=FALSE, threshold=0.01 )
View(train_nn)
colnames(train_nn) <- c("pagina","precio_cat","precio_venta_sinva","pronostico","u_vendidas","venta_neta_sin_iva","costo","utilidad","margen","pedido_real","ratio")
colnames(test_nn) <- c("pagina","precio_cat","precio_venta_sinva","pronostico","u_vendidas","venta_neta_sin_iva","costo","utilidad","margen","pedido_real","ratio")
nn_model <- neuralnet(u_vendidas~., data = train_nn, hidden=c(4,3,2,1), linear.output=FALSE, threshold=0.01 )
nn_model$result.matrix
nn_model$data
nn_model$response
plot(nn_model)
train_nn$results <- nn_model$response
View(train_nn)
nn_model$covariate
pred <- compute(nn_model, test_nn)
pred$neurons
pred$net.result
?compute
train_nn$results <- pred$net.result
View(faltantes)
p_1 <- subset(PagCentroamerica, Producto == "4123310128 ")
p_1 <- p_1[,num <- unlist(lapply(PagCentroamerica, is.numeric))]
p_1$Pronostico <- NULL
colnames(p_1) <- c("unidades_vendidas", "venta_neta_sin_iva", "utilidad", "margen", "pedido_real", "ratio")
max_1 = apply(p_1 , 2 , max)
min_1 = apply(p_1, 2 , min)
scaled_1 = as.data.frame(scale(p_1, center = min_1, scale = max_1 - min_1))
smp_size_1 <- floor(0.80 * nrow(p_1))
train_ind_1 <- sample(seq_len(nrow(p_1)), size = smp_size_1)
test_1 <- scaled_1[-train_ind_1, ]
test_1 <- as.data.frame(test_1)
nn_model_1 <- neuralnet(unidades_vendidas ~., data = train_1, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
library(neuralnet)
nn_model_1 <- neuralnet(unidades_vendidas ~., data = train_1, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
train_1 <- scaled_1[train_ind_1, ]
nn_model_1 <- neuralnet(unidades_vendidas ~., data = train_1, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
train_1 <- scaled_1[train_ind_1, ]
test_1 <- scaled_1[-train_ind_1, ]
test_1 <- as.data.frame(test_1)
nn_model_1 <- neuralnet(unidades_vendidas ~., data = train_1, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
is.na(train_1)
p_1 <- subset(PagCentroamerica, Producto == "4123310128 ")
p_1 <- p_1[,num <- unlist(lapply(PagCentroamerica, is.numeric))]
p_1$Pronostico <- NULL
max_1 = apply(p_1 , 2 , max)
min_1 = apply(p_1, 2 , min)
scaled_1 = as.data.frame(scale(p_1, center = min_1, scale = max_1 - min_1))
## TRAIN Y TEST 4123310128
smp_size_1 <- floor(0.80 * nrow(p_1))
train_ind_1 <- sample(seq_len(nrow(p_1)), size = smp_size_1)
train_1 <- scaled_1[train_ind_1, ]
test_1 <- scaled_1[-train_ind_1, ]
test_1 <- as.data.frame(test_1)
nn_model_1 <- neuralnet(unidades_vendidas ~., data = train_1, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
nn_model_1 <- neuralnet(Unidades.Vendidas ~., data = train_1, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
nn_model_1 <- neuralnet(Unidades.Vendidas~., data = train_1, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
train_1<- as.data.frame(train_1)
nn_model_1 <- neuralnet(Unidades.Vendidas~., data = train_1, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
View(train_1)
colnames(p_1) <- c("pagina","precio_cat","precio_ven_siva","unidades_vendidas", "venta_neta_sin_iva","costo","utilidad", "margen", "pedido_real", "ratio")
max_1 = apply(p_1 , 2 , max)
min_1 = apply(p_1, 2 , min)
scaled_1 = as.data.frame(scale(p_1, center = min_1, scale = max_1 - min_1))
## TRAIN Y TEST 4123310128
smp_size_1 <- floor(0.80 * nrow(p_1))
train_ind_1 <- sample(seq_len(nrow(p_1)), size = smp_size_1)
train_1 <- scaled_1[train_ind_1, ]
test_1 <- scaled_1[-train_ind_1, ]
test_1 <- as.data.frame(test_1)
nn_model_1 <- neuralnet(unidades_vendidas ~., data = train_1, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
plot(nn_model_1, arrow.length=0.13)
?neuralnet
predict_testNN_1 = compute(nn_model_1, test_1)
predict_testNN_1 = (predict_testNN_1$net.result * (max(train_1$unidades_vendidas) - min(train_1$unidades_vendidas))) + min(train_1$unidades_vendidas)
test_1_unscale <- test_1
test_1_unscale$unidades_vendidas <- predict_testNN_1
ps_1 <- unscale(test_1, center = min_1, scale = max_1 - min_1)
ps2_1 <- unscale(test_1_unscale, center = min_1, scale = max_1 - min_1)
library(forecast)
library(tseries)
library(fUnitRoots)
library(ggfortify)
library(xts)
ps_1 <- unscale(test_1, center = min_1, scale = max_1 - min_1)
ps2_1 <- unscale(test_1_unscale, center = min_1, scale = max_1 - min_1)
comparasion_1 <- data.frame(actual=ps_1$unidades_vendidas, pred=ps2_1$unidades_vendidas)
View(comparasion_1)
?neuralnet
plot(nn_model_1, arrow.length=0.13)
p_2 <- subset(PagCentroamerica, Producto == "4123660214 ")
p_2 <- p_2[,num <- unlist(lapply(PagCentroamerica, is.numeric))]
p_2$Pronostico <- NULL
colnames(p_2) <- c("pagina","precio_cat","precio_ven_siva","unidades_vendidas", "venta_neta_sin_iva","costo","utilidad", "margen", "pedido_real", "ratio")
max_2 = apply(p_2 , 2 , max)
min_2 = apply(p_2, 2 , min)
scaled_2 = as.data.frame(scale(p_2, center = min_2, scale = max_2 - min_2))
smp_size_2 <- floor(0.80 * nrow(p_2))
train_ind_2 <- sample(seq_len(nrow(p_2)), size = smp_size_2)
train_2 <- scaled_2[train_ind_2, ]
test_2 <- scaled_2[-train_ind_2, ]
test_2 <- as.data.frame(test_2)
nn_model_2 <- neuralnet(unidades_vendidas ~., data = train_2, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
plot(nn_model_2, arrow.length=0.13)
predict_testNN_2 = compute(nn_model_2, test_2)
predict_testNN_2 = (predict_testNN_2$net.result * (max(train_2$unidades_vendidas) - min(train_2$unidades_vendidas))) + min(train_2$unidades_vendidas)
test_2_unscale <- test_2
test_2_unscale$unidades_vendidas <- predict_testNN_2
ps_2 <- unscale(test_2, center = min_2, scale = max_2 - min_2)
ps2_2 <- unscale(test_2_unscale, center = min_2, scale = max_2 - min_2)
comparasion_2 <- data.frame(actual=ps_2$unidades_vendidas, pred=ps2_2$unidades_vendidas)
View(comparasion_2)
p_3 <- subset(PagCentroamerica, Producto == "4123530132 ")
p_3 <- p_3[,num <- unlist(lapply(PagCentroamerica, is.numeric))]
p_3$Pronostico <- NULL
colnames(p_3) <- c("pagina","precio_cat","precio_ven_siva","unidades_vendidas", "venta_neta_sin_iva","costo","utilidad", "margen", "pedido_real", "ratio")
max_3 = apply(p_3 , 2 , max)
min_3 = apply(p_3, 2 , min)
scaled_3 = as.data.frame(scale(p_3, center = min_3, scale = max_3 - min_3))
smp_size_3 <- floor(0.80 * nrow(p_3))
train_ind_3 <- sample(seq_len(nrow(p_3)), size = smp_size_3)
train_3 <- scaled_3[train_ind_3, ]
test_3 <- scaled_3[-train_ind_3, ]
test_3 <- as.data.frame(test_3)
nn_model_3 <- neuralnet(unidades_vendidas ~., data = train_3, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
plot(nn_model_3, arrow.length=0.13)
predict_testNN_3 = compute(nn_model_3, test_3)
predict_testNN_3 = (predict_testNN_3$net.result * (max(train_3$unidades_vendidas) - min(train_3$unidades_vendidas))) + min(train_3$unidades_vendidas)
#plot(test_3$unidades_vendidas, predict_testNN_3, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")
#abline(0,1)
test_3_unscale <- test_3
test_3_unscale$unidades_vendidas <- predict_testNN_3
ps_3 <- unscale(test_3, center = min_3, scale = max_3 - min_3)
ps2_3 <- unscale(test_3_unscale, center = min_3, scale = max_3 - min_3)
comparasion_3 <- data.frame(actual=ps_3$unidades_vendidas, pred=ps2_3$unidades_vendidas)
View(comparasion_3)
p_4 <- subset(PagCentroamerica, Producto == "4123660107 ")
p_4 <- p_4[,num <- unlist(lapply(PagCentroamerica, is.numeric))]
p_4$Pronostico <- NULL
colnames(p_4) <- c("pagina","precio_cat","precio_ven_siva","unidades_vendidas", "venta_neta_sin_iva","costo","utilidad", "margen", "pedido_real", "ratio")
max_4 = apply(p_4 , 2 , max)
min_4 = apply(p_4, 2 , min)
scaled_4 = as.data.frame(scale(p_4, center = min_4, scale = max_4 - min_4))
## TRAIN Y TEST 4123310125
smp_size_4 <- floor(0.80 * nrow(p_4))
train_ind_4 <- sample(seq_len(nrow(p_4)), size = smp_size_4)
train_4 <- scaled_4[train_ind_4, ]
test_4 <- scaled_4[-train_ind_4, ]
test_4 <- as.data.frame(test_4)
nn_model_4 <- neuralnet(unidades_vendidas ~., data = train_4, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
plot(nn_model_4, arrow.length=0.13)
predict_testNN_4 = compute(nn_model_4, test_4)
predict_testNN_4 = (predict_testNN_4$net.result * (max(train_4$unidades_vendidas) - min(train_4$unidades_vendidas))) + min(train_4$unidades_vendidas)
#plot(test_4$unidades_vendidas, predict_testNN_4, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")
#abline(0,1)
test_4_unscale <- test_4
test_4_unscale$unidades_vendidas <- predict_testNN_4
ps_4 <- unscale(test_4, center = min_4, scale = max_4 - min_4)
ps2_4 <- unscale(test_4_unscale, center = min_4, scale = max_4 - min_4)
comparasion_4 <- data.frame(actual=ps_4$unidades_vendidas, pred=ps2_4$unidades_vendidas)
View(comparasion_4)
p_5 <- subset(PagCentroamerica, Producto == "4123660489 ")
p_5 <- p_5[,num <- unlist(lapply(PagCentroamerica, is.numeric))]
p_5$Pronostico <- NULL
colnames(p_5) <- c("pagina","precio_cat","precio_ven_siva","unidades_vendidas", "venta_neta_sin_iva","costo","utilidad", "margen", "pedido_real", "ratio")
max_5 = apply(p_5 , 2 , max)
min_5 = apply(p_5, 2 , min)
scaled_5 = as.data.frame(scale(p_5, center = min_5, scale = max_5 - min_5))
smp_size_5 <- floor(0.80 * nrow(p_5))
train_ind_5 <- sample(seq_len(nrow(p_5)), size = smp_size_5)
train_5 <- scaled_5[train_ind_5, ]
test_5 <- scaled_5[-train_ind_5, ]
test_5 <- as.data.frame(test_5)
nn_model_5 <- neuralnet(unidades_vendidas ~., data = train_5, hidden=c(3,2,1), linear.output=TRUE, threshold=0.01 )
plot(nn_model_5, arrow.length=0.13)
predict_testNN_5 = compute(nn_model_5, test_5)
predict_testNN_5 = (predict_testNN_5$net.result * (max(train_5$unidades_vendidas) - min(train_5$unidades_vendidas))) + min(train_5$unidades_vendidas)
#plot(test_5$unidades_vendidas, predict_testNN_5, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")
#abline(0,1)
test_5_unscale <- test_5
test_5_unscale$unidades_vendidas <- predict_testNN_5
ps_5 <- unscale(test_5, center = min_5, scale = max_5 - min_5)
ps2_5 <- unscale(test_5_unscale, center = min_5, scale = max_5 - min_5)
comparasion_5 <- data.frame(actual=ps_5$unidades_vendidas, pred=ps2_5$unidades_vendidas)
View(comparasion_5)
ps_5 <- unscale(test_5, center = min_5, scale = max_5 - min_5)
ps2_5 <- unscale(test_5_unscale, center = min_5, scale = max_5 - min_5)
comparasion_5 <- data.frame(actual=ps_5$unidades_vendidas, pred=ps2_5$unidades_vendidas)
View(comparasion_5)
